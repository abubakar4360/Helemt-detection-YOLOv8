{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**IMPORT ZIP FILES TO EXTRACT DATA**"
   ],
   "metadata": {
    "id": "e8lhXiWMddPB"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzJc3FVxHnKy"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5o6eaiQzK6Hs"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/Python ML useful codes/archive.zip\", 'r')\n",
    "zip_ref.extractall(\"/content/drive/MyDrive/ML/Dataset/\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFAOWMwQHtkm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "size = 0\n",
    "Folderpath = '/content/drive/MyDrive/ML/Helmet Detection/Dataset/val/labels/'\n",
    "x= [(len(files)) for path, dirs, files in os.walk(Folderpath)]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**INSTALLING REQUIRED LIBRARIES**"
   ],
   "metadata": {
    "id": "Eu2QZ69cduaG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0jCnGqmLwlJ"
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "!pip install yolov8\n",
    "!pip install --upgrade pillow==6.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**IMPORTING LIBRARIES**"
   ],
   "metadata": {
    "id": "dC12aOgoAPbC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16ZBrcAPL_n1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "53abbdaa-cf00-4f01-d9be-c4ef0bd6ba5e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "import random\n",
    "!pip install tqdm --upgrade\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**DEFINING PATHS**"
   ],
   "metadata": {
    "id": "UAubXpewAUOZ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Czos2l3MCMC"
   },
   "outputs": [],
   "source": [
    "train_path_img = \"/content/drive/MyDrive/ML/Helmet Detection/NewDataset/train/images/\"\n",
    "train_path_label = \"/content/drive/MyDrive/ML/Helmet Detection/NewDataset/train/Labels/\"\n",
    "val_path_img = \"/content/drive/MyDrive/ML/Helmet Detection/NewDataset/val/images/\"\n",
    "val_path_label = \"/content/drive/MyDrive/ML/Helmet Detection/NewDataset/val/Labels/\"\n",
    "test_path_img = \"/content/drive/MyDrive/ML/Helmet Detection/NewDataset/test/images/\"\n",
    "test_path_label = \"/content/drive/MyDrive/ML/Helmet Detection/NewDataset/test/Labels/\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**SPLITTING DATA INTO TRAIN TEST AND VAL**"
   ],
   "metadata": {
    "id": "9oy3gY4SAZ_E"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def train_test_split(path,neg_path=None, split = 0.1):\n",
    "    files = list(set([name[:-4] for name in os.listdir(path)])) ## removing duplicate names i.e. counting only number of images\n",
    "    random.seed(42)\n",
    "    random.shuffle(files)\n",
    "\n",
    "    test_size = int(len(files) * split)\n",
    "    val_size = int(len(files) * split)\n",
    "    train_size = len(files) - test_size - val_size\n",
    "\n",
    "\n",
    "    ## creating required directories\n",
    "    #os.makedirs(train_path_img, exist_ok = True)\n",
    "    os.makedirs(train_path_label, exist_ok = True)\n",
    "    #os.makedirs(val_path_img, exist_ok = True)\n",
    "    os.makedirs(val_path_label, exist_ok = True)\n",
    "    #os.makedirs(test_path_img, exist_ok = True)\n",
    "    os.makedirs(test_path_label, exist_ok = True)\n",
    "\n",
    "    ### ----------- copying images to train folder\n",
    "    for filex in tqdm(files[:train_size]):\n",
    "      if filex == 'classes':\n",
    "          continue\n",
    "      #shutil.copy2(path + filex + '.png',f\"{train_path_img}/\" + filex + '.png' )\n",
    "      shutil.copy2(path + filex + '.xml', f\"{train_path_label}/\" + filex + '.xml')\n",
    "\n",
    "    if neg_path:\n",
    "        neg_images = list(set([name[:-4] for name in os.listdir(neg_path)])) ## removing duplicate names i.e. counting only number of images\n",
    "        for filex in tqdm(neg_images):\n",
    "            shutil.copy2(neg_path+filex+ \".png\", f\"{train_path_img}/\" + filex + '.png')\n",
    "\n",
    "    ### copytin images to validation folder\n",
    "    for filex in tqdm(files[train_size:4500]):\n",
    "      if filex == 'classes':\n",
    "          continue\n",
    "      # print(\"running\")\n",
    "      #shutil.copy2(path + filex + '.png', f\"{val_path_img}/\" + filex + '.png' )\n",
    "      shutil.copy2(path + filex + '.xml', f\"{val_path_label}/\" + filex + '.xml')\n",
    "\n",
    "    ### copytin images to test folder\n",
    "    for filex in tqdm(files[4500:5000]):\n",
    "      if filex == 'classes':\n",
    "          continue\n",
    "      # print(\"running\")\n",
    "      #shutil.copy2(path + filex + '.png', f\"{test_path_img}/\" + filex + '.png' )\n",
    "      shutil.copy2(path + filex + '.xml', f\"{test_path_label}/\" + filex + '.xml')\n",
    "\n",
    "## spliting the data into train-test and creating train.txt and test.txt files\n",
    "# train_test_split('/content/drive/MyDrive/custom_notebooks/yolo_data/')\n",
    "\n",
    "### for label_tag\n",
    "train_test_split('/content/drive/MyDrive/ML/Dataset/annotations/') ### without negative images"
   ],
   "metadata": {
    "id": "qO__Y8OWy5oP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**FOR DELETING CONTENTS OF ANY DIRECTORY**"
   ],
   "metadata": {
    "id": "OPKQniQWAfzh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os, shutil\n",
    "folder = '/content/drive/MyDrive/ML/Helmet Detection/Dataset/train/labels/'\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ],
   "metadata": {
    "id": "oGO2ATqYMa3j"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TAKING BOUNDING BOXES, NORMALIZING BOUNDING BOXES AND STORING IN THEIR RESPECTIVE NAMES WITH .TXT**\n"
   ],
   "metadata": {
    "id": "4VnxEDXMAlc_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "\n",
    "input_directory = '/content/drive/MyDrive/ML/Dataset/ValLabels/'\n",
    "output_directory = '/content/drive/MyDrive/ML/Helmet Detection/Dataset/val/labels/'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "def normalize_coordinateX(value1,value2, image_size):\n",
    "    dw = np.float32(1. / int(image_size))\n",
    "    dh = np.float32(1. / int(image_size))\n",
    "    x = value1 + (value2 / 2)\n",
    "    x = x * dw\n",
    "    return x\n",
    "\n",
    "def normalize_coordinateY(value1,value2, image_size):\n",
    "    dw = np.float32(1. / int(image_size))\n",
    "    dh = np.float32(1. / int(image_size))\n",
    "    y = value1 + (value2 / 2)\n",
    "    y = y * dw\n",
    "    return x\n",
    "\n",
    "def normalize_coordinateW(value1,value2, image_size):\n",
    "    dw = np.float32(1. / int(image_size))\n",
    "    dh = np.float32(1. / int(image_size))\n",
    "    w = value2 - value1\n",
    "    w = w * dh\n",
    "    return w\n",
    "\n",
    "def normalize_coordinateH(value1,value2, image_size):\n",
    "    dw = np.float32(1. / int(image_size))\n",
    "    dh = np.float32(1. / int(image_size))\n",
    "    h = value2 - value1\n",
    "    h = h * dh\n",
    "    return h\n",
    "\n",
    "def remap_class_label(original_label):\n",
    "    class_mapping = {\n",
    "        'helmet': 0,\n",
    "        'head': 1,\n",
    "        'person': 2,\n",
    "    }\n",
    "    return class_mapping.get(original_label, -1)\n",
    "\n",
    "def extract_bounding_boxes(xml_file_path, image_width, image_height):\n",
    "    tree = ET.parse(xml_file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    bounding_boxes = []\n",
    "    for labels in root.iter('object'):\n",
    "        xmin = int(labels.find('bndbox/xmin').text)\n",
    "        ymin = int(labels.find('bndbox/ymin').text)\n",
    "        xmax = int(labels.find('bndbox/xmax').text)\n",
    "        ymax = int(labels.find('bndbox/ymax').text)\n",
    "\n",
    "        name_element = labels.find('name')\n",
    "        if name_element is None:\n",
    "            print(\"WARNING: Ignoring corrupt image/label: Class name not found\")\n",
    "            continue\n",
    "\n",
    "        original_label = name_element.text\n",
    "        new_label = remap_class_label(original_label)\n",
    "\n",
    "        if new_label == -1:\n",
    "            print(f\"WARNING: Ignoring corrupt image/label: Invalid class label {original_label}\")\n",
    "            continue\n",
    "\n",
    "        # Nomalize the coordinates between 0 and 1\n",
    "        xmax_normalized = normalize_coordinateW(xmin,xmax, image_width)   #w\n",
    "        ymax_normalized = normalize_coordinateH(ymin,ymax, image_height)  #h\n",
    "        xmin_normalized = normalize_coordinateX(xmin,xmax_normalized, image_width)\n",
    "        ymin_normalized = normalize_coordinateY(ymin,ymax_normalized, image_height)\n",
    "\n",
    "\n",
    "\n",
    "        bounding_boxes.append([new_label, xmin_normalized, ymin_normalized, xmax_normalized, ymax_normalized])\n",
    "        #bounding_boxes.append([new_label, xmin, ymin, xmax, ymax])\n",
    "\n",
    "    return bounding_boxes\n",
    "\n",
    "for file in os.listdir(input_directory):\n",
    "    if file.endswith('.xml'):\n",
    "        xml_file_path = os.path.join(input_directory, file)\n",
    "\n",
    "        image_width = 416\n",
    "        image_height = 416\n",
    "\n",
    "        bounding_boxes = extract_bounding_boxes(xml_file_path, image_width, image_height)\n",
    "\n",
    "        # Write bounding boxes to a new file in the output directory\n",
    "        output_file_path = os.path.join(output_directory, os.path.splitext(file)[0] + '.txt')\n",
    "        with open(output_file_path, 'w') as f:\n",
    "            for box in bounding_boxes:\n",
    "                f.write(' '.join(str(coord) for coord in box) + '\\n')\n",
    "\n",
    "print(\"Bounding boxes extracted, normalized, and saved successfully!\")\n"
   ],
   "metadata": {
    "id": "8JsuNsP4RXHy",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "eeee021f-84e2-4dfc-b1d9-7b3c2dcde508"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bounding boxes extracted, normalized, and saved successfully!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**FOR CREDATING LABELS.CACHE FILE FOR TRAINING**"
   ],
   "metadata": {
    "id": "91PKi_cBBA39"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "dic = {}\n",
    "\n",
    "for i in os.listdir('/content/drive/MyDrive/ML/Helmet Detection/Dataset/test/images/'):\n",
    "  with open(f'/content/drive/MyDrive/ML/Helmet Detection/Dataset/test/labels/{i.split(\".png\")[0]}.txt') as annotation:\n",
    "    p = []\n",
    "    for j in annotation.readlines():\n",
    "      arr = list(map(float,j.strip().split()))\n",
    "      p.append(arr)\n",
    "  dic[f'/content/drive/MyDrive/ML/Helmet Detection/Dataset/test/images{i}'] = [np.array(p, dtype=float), (416,416)]\n",
    "\n",
    "torch.save(dic,'/content/drive/MyDrive/ML/Helmet Detection/Dataset/test/labels.cache')"
   ],
   "metadata": {
    "id": "wRxv9i-f1EQ-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**PRETRAINED MODEL**"
   ],
   "metadata": {
    "id": "p6GXKmkaBI1c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g6Kh___fO22-"
   },
   "outputs": [],
   "source": [
    "model = YOLO('/content/drive/MyDrive/ML/Helmet Detection/Dataset/yolov8n.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TRAINING THE DATASET**"
   ],
   "metadata": {
    "id": "psvt7Ok4BM8D"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4E83m5mhNNRO"
   },
   "outputs": [],
   "source": [
    "results = model.train(\n",
    "   data='/content/drive/MyDrive/ML/Helmet Detection/Dataset/data.yaml',\n",
    "   imgsz=640,\n",
    "   epochs=20,\n",
    "   batch=32,\n",
    "   lr0=0.01,\n",
    "   name='/content/drive/MyDrive/ML/Helmet Detection/Training results/Helmet'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**VALIDATING DATASET**"
   ],
   "metadata": {
    "id": "6n_7gQORBQKO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "metrics = model.val()"
   ],
   "metadata": {
    "id": "NdszdIUg8GRy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**WEIGHTS MODEL**"
   ],
   "metadata": {
    "id": "ELk6RZJvH2fr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = YOLO('/content/drive/MyDrive/ML/Helmet Detection/Training results/Helmet_10e/weights/best.pt')"
   ],
   "metadata": {
    "id": "koSBhGB_-SbS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**PREDICTING THE RESULTS*"
   ],
   "metadata": {
    "id": "LZ7xMhueBVBS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!yolo task = detect mode = predict model= model show = True conf =0.5 source = '/content/drive/MyDrive/ML/Helmet Detection/Dataset/test/images/hard_hat_workers1039.png'"
   ],
   "metadata": {
    "id": "JqIGiZuC8Ljf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "path = '/content/iii.jpeg'\n",
    "result = model.predict(path, save=True)"
   ],
   "metadata": {
    "id": "PBYS_odD8G7T"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**PLOTTING IMAGE WITH DETECTIONS USING MATPLOTLIB**"
   ],
   "metadata": {
    "id": "okOX-q3AILcz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "#img = cv2.imread('/content/drive/MyDrive/ML/Helmet Detection/Dataset/test/images/hard_hat_workers1039.png')\n",
    "#img = np.asarray(img)\n",
    "#fig = plt.figure()\n",
    "ax = plt.imshow(pred_in_array)\n"
   ],
   "metadata": {
    "id": "gfzlH2Xle-W-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TRACKING THE STREAMING**\n",
    "\n"
   ],
   "metadata": {
    "id": "KllXz21KITHU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install torchvision==0.14"
   ],
   "metadata": {
    "id": "C4O8ClTQdQ4k"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install bytetracker"
   ],
   "metadata": {
    "id": "Po6jyF7Pl6Fz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!cp -r '/content/runs/detect/track3/demo_bytetrack.avi' '/content/drive/MyDrive/ML/Helmet Detection'    #transfering to new directory"
   ],
   "metadata": {
    "id": "J4wMbP4ci53Q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "video_tracking = model.track('/content/demo.mp4', save = True, conf = 0.45, iou=0.55, persist = True,tracker=\"bytetrack.yaml\")"
   ],
   "metadata": {
    "id": "fHA4Jcoctezm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "69Rqk4OxFJWc"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
